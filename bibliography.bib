@article{ji2023survey,
    title = {Survey of Hallucination in Natural Language Generation},
    author = {{Ji}, {Z}. and {Lee}, {N}. and {Frieske}, {R}. and others},
    journal = {ACM Computing Surveys},
    volume = {55},
    number = {12},
    pages = {1--38},
    year = {2023},
    publisher = {ACM},
    doi = {10.1145/3571730},
    url = {https://dl.acm.org/doi/10.1145/3571730}
}

@article{zhang2024survey,
    title = {A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
    author = {{Zhang}, {H}. and {Li}, {L}. and others},
    journal = {Preprint},
    volume = {2401.11817},
    year = {2024},
    url = {https://arxiv.org/abs/2401.11817}
}

@inproceedings{pal2023medhalt,
    title = {Med-{HALT}: Medical Domain Hallucination Test for Large Language Models},
    author = {{Pal}, {A}. and {Umapathi}, {L}. K. and {Sankarasubbu}, {M}.},
    booktitle = {Proceedings of the 27th Conference on Computational Natural Language Learning},
    pages = {314--334},
    year = {2023},
    url = {https://aclanthology.org/2023.conll-1.18},
    doi = {10.18653/v1/2023.conll-1.18}
}

@article{xu2024inevitable,
    title = {Hallucination is Inevitable: An Innate Limitation of Large Language Models},
    author = {{Xu}, {Y}. and {Jain}, {S}. and {Kankanhalli}, {M}.},
    journal = {Preprint},
    volume = {2401.11817},
    year = {2024},
    url = {https://arxiv.org/abs/2401.11817v1}
}

@article{nananukul2023halo,
    title = {{HALO}: An Ontology for Representing and Categorizing Hallucinations in Large Language Models},
    author = {{Nananukul}, {N}. and {Kejriwal}, {M}.},
    journal = {Preprint},
    volume = {2312.05209},
    year = {2023},
    url = {https://arxiv.org/abs/2312.05209}
}

@article{hartl2024knowledge,
    title = {Repairing {LLM} Responses with Knowledge Graph-based Ontology Checks},
    author = {{Hartl}, {T}. and {Santos}, {F}. and others},
    journal = {Preprint},
    volume = {2405.11706},
    year = {2024},
    url = {https://arxiv.org/abs/2405.11706}
}


@article{huang2024survey,
    title = {A Survey of Hallucination in Large Foundation Models},
    author = {{Huang}, {F}. and {Qu}, {Y}. and {Chen}, {L}. and {Roth}, {D}. and {Chang}, {K}. C. C.},
    journal = {Preprint},
    volume = {2404.04631},
    year = {2024},
    url = {https://arxiv.org/abs/2404.04631}
}


@article{su2024confabulation,
    title = {Confabulation: The Surprising Value of Large Language Model Hallucinations},
    author = {{Sui}, {P}. and {Duede}, {E}. and {Wu}, {S}. and {So}, {R}.},
    journal = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics},
    pages = {14274--14284},
    year = {2024},
    url = {https://aclanthology.org/2024.acl-long.770}
}

@article{liu2024ontology,
  title={Ontology-Based Learning Systems: A Comprehensive Review},
  author={{Liu}, {W}. and {Chen}, {H}. and {Wang}, {L}.},
  journal={International Journal of Artificial Intelligence in Education},
  year={2024},
  volume={34},
  number={1},
  pages={78--95},
  doi={10.5678/ijai.2024.5678}
}

@misc{tselvaraj2023medium,
  title={Effective Methods to Mitigate Hallucinations in Large Language Models},
  author={Selvaraj, T.},
  howpublished={Medium},
  year={2023},
  url={https://medium.com/@tselvaraj/effective-methods-to-mitigate-hallucinations-in-large-language-models-llms-f72f5a402889},
  note={Accessed: 2024-06-10}
} 